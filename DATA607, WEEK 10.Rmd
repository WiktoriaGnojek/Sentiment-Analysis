---
title: "Data 607 - Week 10"
author: "Wiktoria Gnojek"
date: "10/30/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
In Text Mining with R, Chapter 2 looks at Sentiment Analysis.  

In this assignment, you should start by getting the primary example code from chapter 2 working in an R Markdown document.  You should provide a citation to this base code.  You’re then asked to extend the code in two ways:

Work with a different corpus of your choosing, and Incorporate at least one additional sentiment lexicon (possibly from another R package that you’ve found through research).

**I will begin this assignment by citing from the text to show examples of sentimental analysis, and later researching my own package and implementing its code.**

**Initial Code**

The initial code from Chapter 2 can be found at this link from book "Text Mining with R"; https://www.tidytextmining.com/sentiment.html

**Code from Chapter**

The tidytext package provides access to several sentiment lexicons. Three general-purpose lexicons are;

AFINN from Finn Årup Nielsen, bing from Bing Liu and collaborators, and nrc from Saif Mohammad and Peter Turney.

```{r}
library(tidytext)
library(textdata)
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
```
**Sentiment Analysis with Inner Join**

Just a few examples from the chapter;

This portion of the chapter will be looking at the most common joy words inside Emma. 
```{r}
library(janeaustenr)
library(dplyr)
library(stringr)

tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
```

We can see that the top words are postive and have been associated with joy. 

**Ggplot**

Plotting these sentiment scores across the plot trajectory of each novel.
```{r}
library(tidyr)

jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
library(ggplot2)

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

**Comparing the Three Sentiment Dictionaries**

"We now have an estimate of the net sentiment (positive - negative) in each chunk of the novel text for each sentiment lexicon." - Text Mining with R
```{r}
pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice
afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

**Wordclouds**

Looking at the most common words. 
```{r}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

**Researched Package for Analysis**

The package that caught my eye when researching is called SentimentAnalysis Vignette. I liked how simple the package was for the user, and I will demonstrate with a few examples below. The package also allows generation of tailored dictionaries and is already defaulted to convert the running text into a machine-readable format

The info to the package can be found at the link; https://cran.r-project.org/web/packages/SentimentAnalysis/vignettes/SentimentAnalysis.html
```{r}
library(SentimentAnalysis)
```
Automatically detecting paragraphs as either negative or positive. 
```{r}
sentiment <- analyzeSentiment("I found the book to be a horrible and unplesant read.")
convertToBinaryResponse(sentiment)$SentimentQDAP
```
I wanted to try this with reviews. I chose a local Chipotle in my neighborhood, saved a few of their reviews as variables and ran the code. 

Reviews taken from Google at link; https://www.google.com/search?q=chipotle+rego+park&oq=chipotle+rego+par&aqs=chrome.0.0i355i512j46i175i199i512j69i57.4307j0j7&sourceid=chrome&ie=UTF-8
```{r} 
ReviewOne<- analyzeSentiment("My favorite store from the Chipotle franchise. Ive visited 100s of Chipotles before, this one has the right everything. Nice people, good ambiance, you can sit and watch the sky. There are nice little quiet corners where you can just sit and contemplate your thoughts.")
convertToBinaryResponse(ReviewOne)$SentimentQDAP
ReviewTwo <- analyzeSentiment("Barely got any food staff was rude and just throws food on plate with no care and look bothered when you ask for what you want never again.")
convertToBinaryResponse(ReviewTwo)$SentimentQDAP
ReviewThree <- analyzeSentiment("Terrible customer service, lazy staff. The girl making my bowl didn’t want to be there because she was acting lifeless or without energy or something. Ugh. So annoying.")
convertToBinaryResponse(ReviewThree)$SentimentQDAP
```
The package was able to correctly analyze each review judging whether it was positive or negative. 

We are also able to create vectors using the package so that I don't have to write each review as a new variable. 
```{r}
reviews <- c("My favorite store from the Chipotle franchise. Ive visited 100s of Chipotles before, this one has the right everything. Nice people, good ambiance, you can sit and watch the sky. There are nice little quiet corners where you can just sit and contemplate your thoughts.","Barely got any food staff was rude and just throws food on plate with no care and look bothered when you ask for what you want never again.", "Terrible customer service, lazy staff. The girl making my bowl didn’t want to be there because she was acting lifeless or without energy or something. Ugh. So annoying.")
sentiment <- analyzeSentiment(reviews)
convertToDirection(sentiment$SentimentQDAP)
```
The code ran the same final answers as above, again being accurate. 

There is also an option for neutral reviews, which I tested using a review that had 3 stars, and was neither positive nor negative. 
```{r}
reviewsChipotle <- c("My favorite store from the Chipotle franchise. Ive visited 100s of Chipotles before, this one has the right everything. Nice people, good ambiance, you can sit and watch the sky. There are nice little quiet corners where you can just sit and contemplate your thoughts.","Barely got any food staff was rude and just throws food on plate with no care and look bothered when you ask for what you want never again.", "Terrible customer service, lazy staff. The girl making my bowl didn’t want to be there because she was acting lifeless or without energy or something. Ugh. So annoying." , "Like most chipotle restaurants...great food, ok price, service lacking" )
sentiment <- analyzeSentiment(reviewsChipotle)
convertToDirection(sentiment$SentimentQDAP)
```
Again, showing accuracy and a new rating system of neutral. 

**Dictionaries Inside the Package, and their Rating**

The package contains a few built-in dictionaries that are used for lists of words, computations of positive to negative, and continuous sentiment scores. 

These are stored as; SentimentDictionaryWordlist, SentimentDictionaryBinary, and SentimentDictionaryWeighted. 

Examples of this; 
```{r}
# list
wordlist <- SentimentDictionary(c("happy", "sad", "excited"))
summary(wordlist)
#binary 
wordbinary <- SentimentDictionaryBinary(c("happy", "sad", "excited"),
                               c("laughing", "crying"))
summary(wordbinary)
```
We are able to count strings of words, as well as rate percentages of negative vs. positive. 

We are also able to plot using functions like "plotSentimentResponse" and "plotSentiment". 

A few more fun functions include;

1) Saving and reloading dictionaries using read() and write().

2) Performance evaluation using compareDictionary(), which compares the generated dictionary to dictionaries from the literature. 

3) Word counting using countWords(). 

4) Being able to use the package with languages other then English. This can be done by changing the language parameter, and loading a dictionary. 

**Trying to see if this package works with the code from chapter 2**

Looking at paragraphs, from Chapter 2 we are using code that generates a sentence from Pride and Prejudice. 
```{r}
p_and_p_sentences <- tibble(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")
first_sentance <- p_and_p_sentences$sentence[23]
first_sentance
# word count using SentimentAnalysis
countWords(first_sentance)
# rating system using SentimentAnalysis library
sentiment_one <- analyzeSentiment(first_sentance)
convertToBinaryResponse(sentiment_one)$SentimentQDAP
# word list using SentimentAnalysis library
wordList <- SentimentDictionaryWordlist(first_sentance)
summary(wordList)
```

**Conclusion**

From a few functions above, the library is compatible with the initial chapter 2 code. The extra step is saving the chapter two code as a variable before applying it to the SentimentAnalysis library. There are many libraries that are either updated to make the code more user friendly, or ones that have you write out a little more of what final result you are trying to achieve. 





